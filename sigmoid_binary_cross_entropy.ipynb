{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyManfy9nAOoSQjfd9W8geqz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["In this code, predicting mulitple labels from multiple classes\n","will be conducted by using sigmoid as a final activation function in addition to binary cross entropy as the cost function"],"metadata":{"id":"EqVLxT1GVQer"}},{"cell_type":"markdown","source":["data description: numbers from 1 - 20 represened as binary digits\n","\n","labels description: numbers from 1 to 10 will have class 0 and numbers from 11-20 \n","will have class 1, even numbers will have the 1 and odd will have 0\n","example:\n","label : 110 >> odd number and exits in range (1,10)"],"metadata":{"id":"P1SEXI8ZWjz2"}},{"cell_type":"code","source":["import numpy as np \n","import numpy.random as random"],"metadata":{"id":"RKpq7d--VtmZ","executionInfo":{"status":"ok","timestamp":1677509233821,"user_tz":-60,"elapsed":5,"user":{"displayName":"HAITHAM AL-TOSAIMI","userId":"14079608149427840165"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["x = np.array( ([[0,0,0,0,1],[0,0,0,1,0],[0,0,0,1,1],[0,0,1,0,0],[0,0,1,0,1],\n","               [0,0,1,1,0],[0,0,1,1,1],[0,1,0,0,0],[0,1,0,0,1],[0,1,0,1,0],\n","               [0,1,0,1,1],[0,1,1,0,0],[0,1,1,0,1],[0,1,1,1,0],[0,1,1,1,1],[1,0,0,0,0],\n","               [1,0,0,0,1],[1,0,0,1,0],[1,0,0,1,1],[1,0,1,0,0]]) )\n","\n","\n","y = np.array(([ [1,1,0],[1,0,1],[1,1,0],[1,0,1],[1,1,0],\n","               [1,0,1],[1,1,0],[1,0,1],\n","               [1,1,0],[1,0,1],[0,1,0],[0,0,1],[0,1,0],[0,0,1],[0,1,0],[0,0,1],\n","               [0,1,0],[0,0,1],[0,1,0],[0,0,1]]))\n"],"metadata":{"id":"_z_wv0qmWIGJ","executionInfo":{"status":"ok","timestamp":1677511752237,"user_tz":-60,"elapsed":14,"user":{"displayName":"HAITHAM AL-TOSAIMI","userId":"14079608149427840165"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"305p6x3pfH1m","executionInfo":{"status":"ok","timestamp":1677511771532,"user_tz":-60,"elapsed":372,"user":{"displayName":"HAITHAM AL-TOSAIMI","userId":"14079608149427840165"}},"outputId":"28f46b43-37ea-45ae-910e-eee5b322e7b2"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(20, 3)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["def forward_pass(x, w1, b1, w2, b2, y):\n","  eps = 1e-6\n","  hidden_1 = x.dot(w1.T) + b1\n","  hidden_1_sig = 1/(1+np.exp(-hidden_1))\n","  hidden_2 = hidden_1_sig.dot(w2) + b2\n","  hidden_2_sig = 1/(1 + np.exp(-hidden_2) + eps)\n","  Loss = -np.mean( np.multiply(y, np.log(hidden_2_sig)) + np.multiply((1-y), np.log(1-hidden_2_sig)))\n","  print(\" the loss is: \", Loss.sum())\n","  return hidden_1, hidden_1_sig, hidden_2, hidden_2_sig\n"],"metadata":{"id":"h1XY-0knWiVL","executionInfo":{"status":"ok","timestamp":1677511846674,"user_tz":-60,"elapsed":4,"user":{"displayName":"HAITHAM AL-TOSAIMI","userId":"14079608149427840165"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def backward_pass(x, h2_sig, h2, h1_sig, h1, y):\n","  dLdw2 = (h2_sig - y).T.dot(h1_sig).T\n","  dLdw1 = (( (h2_sig - y).dot(w2.T)) *(np.multiply(h1_sig, (1-h1_sig)))).T.dot(x) \n","  dLdb2 = (h2_sig - y).sum(axis=0)\n","  dLdb1 = ((h2_sig - y).dot(w2.T)* (np.multiply(h1_sig, (1-h1_sig)))).sum(axis=0)\n","\n","  return dLdw2, dLdw1, dLdb2, dLdb1\n","\n"],"metadata":{"id":"_jcZTuCHbF3n","executionInfo":{"status":"ok","timestamp":1677511843935,"user_tz":-60,"elapsed":20,"user":{"displayName":"HAITHAM AL-TOSAIMI","userId":"14079608149427840165"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def update_parameters(w1, w2, dw2, dw1, b1, b2, db1, db2, learning_rate):\n","  new_w1 = w1 - dw1 * learning_rate\n","  new_w2 = w2 - dw2 * learning_rate\n","  new_b1 = b1 - db1 * learning_rate\n","  new_b2 = b2 - db2 * learning_rate\n","  return new_w1, new_w2, new_b1, new_b2\n","\n","\n","\n","\n"],"metadata":{"id":"Qy6M7nY2cfJK","executionInfo":{"status":"ok","timestamp":1677511123787,"user_tz":-60,"elapsed":19,"user":{"displayName":"HAITHAM AL-TOSAIMI","userId":"14079608149427840165"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["w1 = random.uniform(-1,1, (10,5))\n","b1 = random.uniform(-1,1,(1,10))\n","w2 = random.uniform(-1,1, (10,3))\n","b2 = random.uniform(-1,1, (3))"],"metadata":{"id":"ehwVmIqbdFz_","executionInfo":{"status":"ok","timestamp":1677511857095,"user_tz":-60,"elapsed":873,"user":{"displayName":"HAITHAM AL-TOSAIMI","userId":"14079608149427840165"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["for i in range(100):\n","  h1, h1_sig, h2, h2_sig=forward_pass(x, w1, b1, w2, b2, y)\n","  dw2, dw1, db2, db1 = backward_pass(x, h2_sig, h2, h1_sig, h1, y)\n","  learning_rate = 1e-3\n","  new_w1, new_w2, new_b1, new_b2 = update_parameters(w1, w2, dw2, dw1, b1, b2, db1, db2, learning_rate)\n","  w2, w1, b1, b2 = new_w2, new_w1, new_b1, new_b2\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cb1Lt-R0dXyy","executionInfo":{"status":"ok","timestamp":1677511925169,"user_tz":-60,"elapsed":394,"user":{"displayName":"HAITHAM AL-TOSAIMI","userId":"14079608149427840165"}},"outputId":"d16c25dd-66a7-4fed-834b-ff4372a0ca00"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":[" the loss is:  0.008344129422058554\n"," the loss is:  0.008343748154119318\n"," the loss is:  0.008343366916606606\n"," the loss is:  0.008342985709517026\n"," the loss is:  0.00834260453284717\n"," the loss is:  0.008342223386593609\n"," the loss is:  0.008341842270752927\n"," the loss is:  0.00834146118532168\n"," the loss is:  0.008341080130296481\n"," the loss is:  0.008340699105673925\n"," the loss is:  0.008340318111450565\n"," the loss is:  0.008339937147622985\n"," the loss is:  0.008339556214187782\n"," the loss is:  0.00833917531114155\n"," the loss is:  0.008338794438480845\n"," the loss is:  0.008338413596202302\n"," the loss is:  0.008338032784302452\n"," the loss is:  0.008337652002777909\n"," the loss is:  0.008337271251625266\n"," the loss is:  0.008336890530841088\n"," the loss is:  0.008336509840422007\n"," the loss is:  0.008336129180364547\n"," the loss is:  0.008335748550665371\n"," the loss is:  0.008335367951321015\n"," the loss is:  0.008334987382328093\n"," the loss is:  0.00833460684368318\n"," the loss is:  0.008334226335382862\n"," the loss is:  0.008333845857423788\n"," the loss is:  0.008333465409802494\n"," the loss is:  0.008333084992515576\n"," the loss is:  0.00833270460555965\n"," the loss is:  0.00833232424893128\n"," the loss is:  0.008331943922627085\n"," the loss is:  0.008331563626643662\n"," the loss is:  0.008331183360977617\n"," the loss is:  0.008330803125625497\n"," the loss is:  0.008330422920583926\n"," the loss is:  0.00833004274584951\n"," the loss is:  0.00832966260141885\n"," the loss is:  0.008329282487288531\n"," the loss is:  0.008328902403455164\n"," the loss is:  0.00832852234991533\n"," the loss is:  0.008328142326665617\n"," the loss is:  0.008327762333702662\n"," the loss is:  0.008327382371023036\n"," the loss is:  0.008327002438623363\n"," the loss is:  0.00832662253650023\n"," the loss is:  0.00832624266465023\n"," the loss is:  0.008325862823069992\n"," the loss is:  0.008325483011756087\n"," the loss is:  0.008325103230705141\n"," the loss is:  0.008324723479913747\n"," the loss is:  0.008324343759378515\n"," the loss is:  0.008323964069096041\n"," the loss is:  0.008323584409062945\n"," the loss is:  0.008323204779275811\n"," the loss is:  0.008322825179731272\n"," the loss is:  0.008322445610425907\n"," the loss is:  0.008322066071356346\n"," the loss is:  0.008321686562519193\n"," the loss is:  0.008321307083911041\n"," the loss is:  0.008320927635528516\n"," the loss is:  0.008320548217368209\n"," the loss is:  0.008320168829426735\n"," the loss is:  0.00831978947170075\n"," the loss is:  0.00831941014418677\n"," the loss is:  0.008319030846881485\n"," the loss is:  0.008318651579781462\n"," the loss is:  0.008318272342883364\n"," the loss is:  0.008317893136183743\n"," the loss is:  0.008317513959679244\n"," the loss is:  0.008317134813366472\n"," the loss is:  0.008316755697242063\n"," the loss is:  0.008316376611302613\n"," the loss is:  0.008315997555544716\n"," the loss is:  0.008315618529965027\n"," the loss is:  0.008315239534560124\n"," the loss is:  0.008314860569326683\n"," the loss is:  0.008314481634261243\n"," the loss is:  0.008314102729360475\n"," the loss is:  0.00831372385462097\n"," the loss is:  0.008313345010039377\n"," the loss is:  0.008312966195612283\n"," the loss is:  0.00831258741133631\n"," the loss is:  0.008312208657208102\n"," the loss is:  0.00831182993322426\n"," the loss is:  0.008311451239381411\n"," the loss is:  0.00831107257567617\n"," the loss is:  0.00831069394210516\n"," the loss is:  0.008310315338664996\n"," the loss is:  0.008309936765352341\n"," the loss is:  0.008309558222163765\n"," the loss is:  0.008309179709095935\n"," the loss is:  0.008308801226145432\n"," the loss is:  0.008308422773308925\n"," the loss is:  0.00830804435058299\n"," the loss is:  0.008307665957964306\n"," the loss is:  0.008307287595449466\n"," the loss is:  0.0083069092630351\n"," the loss is:  0.008306530960717826\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"TOLdt5RIeS4w"},"execution_count":null,"outputs":[]}]}